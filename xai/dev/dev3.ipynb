{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "def load_images_from_directory(root_path: str):\n",
    "    \"\"\"\n",
    "    Load images from a directory with subfolders named after ImageNet labels.\n",
    "    Return a list of (image, label, filename) triples.\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "    \n",
    "    # Iterate over each subfolder\n",
    "    for label in os.listdir(root_path):\n",
    "        label_path = os.path.join(root_path, label)\n",
    "        \n",
    "        # Check if it's indeed a folder\n",
    "        if os.path.isdir(label_path):\n",
    "            \n",
    "            # Iterate over each image in the subfolder\n",
    "            for image_file in os.listdir(label_path):\n",
    "                image_path = os.path.join(label_path, image_file)\n",
    "                \n",
    "                # Check if it's an image file\n",
    "                if image_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    img = Image.open(image_path)\n",
    "                    dataset.append((img, label, image_file))  # Add image filename here\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "dataset_path = \"/home/workstation/code/XAImethods/pytorch-grad-cam/ImageNet-Mini/images\"\n",
    "dataset = load_images_from_directory(dataset_path)\n",
    "\n",
    "\n",
    "with open(\"/home/workstation/code/XAImethods/pytorch-grad-cam/ImageNet-Mini/imagenet_class_index.json\", \"r\") as f:\n",
    "    imagenet_class_index = json.load(f)\n",
    "\n",
    "\n",
    "label_to_index_description = {v[0]: (k, v[1]) for k, v in imagenet_class_index.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from codecarbon import EmissionsTracker\n",
    "from torchvision import transforms\n",
    "from datasets import load_dataset\n",
    "from pytorch_grad_cam import run_dff_on_image\n",
    "from pytorch_grad_cam import (\n",
    "    GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus,\n",
    "    AblationCAM, XGradCAM, EigenCAM, EigenGradCAM,\n",
    "    LayerCAM, FullGrad, GradCAMElementWise\n",
    ")\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from typing import List, Callable, Optional\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA!\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU!\")\n",
    "# dataset = load_dataset(\"huggingface/cats-image\")\n",
    "# image = dataset[\"test\"][\"image\"][0]\n",
    "# img_tensor = transforms.ToTensor()(image)\n",
    "\n",
    "\"\"\" Model wrapper to return a tensor\"\"\"\n",
    "class HuggingfaceToTensorModelWrapper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(HuggingfaceToTensorModelWrapper, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).logits\n",
    "\n",
    "\"\"\" Translate the category name to the category index.\n",
    "    Some models aren't trained on Imagenet but on even larger datasets,\n",
    "    so we can't just assume that 761 will always be remote-control.\n",
    "\n",
    "\"\"\"\n",
    "def category_name_to_index(model, category_name):\n",
    "    name_to_index = dict((v, k) for k, v in model.config.id2label.items())\n",
    "    return name_to_index[category_name]\n",
    "    \n",
    "\"\"\" Helper function to run GradCAM on an image and create a visualization.\n",
    "    (note to myself: this is probably useful enough to move into the package)\n",
    "    If several targets are passed in targets_for_gradcam,\n",
    "    e.g different categories,\n",
    "    a visualization for each of them will be created.\n",
    "    \n",
    "\"\"\"\n",
    "# def run_grad_cam_on_image(model: torch.nn.Module,\n",
    "#                           target_layer: torch.nn.Module,\n",
    "#                           targets_for_gradcam: List[Callable],\n",
    "#                           reshape_transform: Optional[Callable],\n",
    "#                           input_tensor: torch.nn.Module=img_tensor,\n",
    "#                           input_image: Image=image,\n",
    "#                           method: Callable=GradCAM):\n",
    "#     with method(model=HuggingfaceToTensorModelWrapper(model),\n",
    "#                  target_layers=[target_layer],\n",
    "#                  reshape_transform=reshape_transform) as cam:\n",
    "\n",
    "#         # Replicate the tensor for each of the categories we want to create Grad-CAM for:\n",
    "#         repeated_tensor = input_tensor[None, :].repeat(len(targets_for_gradcam), 1, 1, 1)\n",
    "\n",
    "#         batch_results = cam(input_tensor=repeated_tensor,\n",
    "#                             targets=targets_for_gradcam)\n",
    "#         results = []\n",
    "#         for grayscale_cam in batch_results:\n",
    "#             visualization = show_cam_on_image(np.float32(input_image)/255,\n",
    "#                                               grayscale_cam,\n",
    "#                                               use_rgb=True)\n",
    "#             # Make it weight less in the notebook:\n",
    "#             visualization = cv2.resize(visualization,\n",
    "#                                        (visualization.shape[1]//2, visualization.shape[0]//2))\n",
    "#             results.append(visualization)\n",
    "#         return np.hstack(results)\n",
    "    \n",
    "def run_grad_cam_on_image(model: torch.nn.Module,\n",
    "                          target_layer: torch.nn.Module,\n",
    "                          targets_for_gradcam: List[Callable],\n",
    "                          input_tensor: torch.nn.Module,\n",
    "                          input_image: Image,\n",
    "                          reshape_transform: Optional[Callable] = None,\n",
    "                          method: Callable = GradCAM):\n",
    "    with method(model=HuggingfaceToTensorModelWrapper(model),\n",
    "                target_layers=[target_layer],\n",
    "                reshape_transform=reshape_transform) as cam:\n",
    "\n",
    "        # Replicate the tensor for each of the categories we want to create Grad-CAM for:\n",
    "        repeated_tensor = input_tensor[None, :].repeat(len(targets_for_gradcam), 1, 1, 1)\n",
    "\n",
    "        batch_results = cam(input_tensor=repeated_tensor,\n",
    "                            targets=targets_for_gradcam)\n",
    "        results = []\n",
    "        grayscale_cams = []\n",
    "        for grayscale_cam in batch_results:\n",
    "            visualization = show_cam_on_image(np.float32(input_image) / 255,\n",
    "                                              grayscale_cam,\n",
    "                                              use_rgb=True)\n",
    "            # Make it weight less in the notebook:\n",
    "            visualization = cv2.resize(visualization,\n",
    "                                       (visualization.shape[1] // 2, visualization.shape[0] // 2))\n",
    "            results.append(visualization)\n",
    "            grayscale_cams.append(grayscale_cam)\n",
    "        return np.hstack(results), grayscale_cams\n",
    "    \n",
    "def print_top_categories(model, img_tensor, top_k=5):\n",
    "    logits = model(img_tensor.unsqueeze(0)).logits\n",
    "    indices = logits.cpu()[0, :].detach().numpy().argsort()[-top_k :][::-1]\n",
    "    for i in indices:\n",
    "        print(f\"Predicted class {i}: {model.config.id2label[i]}\")\n",
    "\n",
    "# Generate targets_for_gradcam based on model's predictions\n",
    "def get_top_k_targets(model, input_tensor, k=5):\n",
    "    logits = model(input_tensor.unsqueeze(0)).logits\n",
    "    top_k_indices = logits[0].argsort(descending=True)[:k].cpu().numpy()\n",
    "    return [ClassifierOutputTarget(index) for index in top_k_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apple/mobilevit-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from tqdm import tqdm\n",
    "# from collections import defaultdict\n",
    "# import gc\n",
    "\n",
    "# # Import the necessary modules\n",
    "# from transformers import MobileViTForImageClassification\n",
    "\n",
    "# tracker = EmissionsTracker()\n",
    "# tracker.start()\n",
    "\n",
    "# # Load the model and send it to the appropriate device\n",
    "# model = MobileViTForImageClassification.from_pretrained(\"apple/mobilevit-small\").to(device)\n",
    "# target_layer = model.mobilevit.conv_1x1_exp\n",
    "\n",
    "# # Define the transformation to convert images to tensor\n",
    "# transform = transforms.ToTensor()\n",
    "\n",
    "# # Define the directory to save results\n",
    "# save_dir = \"/home/workstation/code/XAImethods/pytorch-grad-cam/apple/mobilevit-small\"\n",
    "# # Ensure the directory exists\n",
    "# if not os.path.exists(save_dir):\n",
    "#     os.makedirs(save_dir)\n",
    "# # Convert any grayscale image to RGB\n",
    "# def ensure_rgb(img):\n",
    "#     if img.mode != 'RGB':\n",
    "#         return img.convert('RGB')\n",
    "#     return img\n",
    "\n",
    "# # Iterate over all images in the dataset\n",
    "# for idx, (img, label, filename) in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "\n",
    "#     torch.cuda.empty_cache()\n",
    "#     img = ensure_rgb(img)  # Ensure the image is in RGB format\n",
    "#     img_tensor = transform(img).to(device)\n",
    "#     # Dynamically generate targets_for_gradcam based on model's prediction\n",
    "#     #dynamic_targets_for_gradcam = get_top_k_targets(model, img_tensor)\n",
    "\n",
    "#     # 使用标签获取索引和描述\n",
    "#     index_description = label_to_index_description.get(label)\n",
    "#     if index_description is None:\n",
    "#         print(f\"Warning: Label '{label}' not found in the JSON file!\")\n",
    "#         continue\n",
    "    \n",
    "#     index_str, description = index_description\n",
    "#     index = int(index_str)  # 将字符串索引转换为整数\n",
    "\n",
    "#     dynamic_targets_for_gradcam = [ClassifierOutputTarget(index)]\n",
    "\n",
    "#     gradcam_result, grayscale_cams = run_grad_cam_on_image(\n",
    "#         model=model,\n",
    "#         target_layer=target_layer,\n",
    "#         targets_for_gradcam=dynamic_targets_for_gradcam,\n",
    "#         input_tensor=img_tensor,\n",
    "#         input_image=img,\n",
    "#         reshape_transform=None\n",
    "#     )\n",
    "\n",
    "#     # Extract top predictions\n",
    "#     logits = model(img_tensor.unsqueeze(0)).logits\n",
    "#     top_indices = logits[0].argsort(descending=True)[:5].cpu().numpy()\n",
    "#     predictions = {index: {\"score\": logits[0][index].item(), \"label\": model.config.id2label[index]} for index in top_indices}\n",
    "    \n",
    "#     # Define individual directory for this image using the original filename\n",
    "#     img_dir = os.path.join(save_dir, filename.rsplit('.', 1)[0])  # Remove file extension from filename\n",
    "#     if not os.path.exists(img_dir):\n",
    "#         os.makedirs(img_dir)\n",
    "    \n",
    "#     # Define file names\n",
    "#     img_name = os.path.join(img_dir, \"original.jpg\")\n",
    "#     gradcam_name = os.path.join(img_dir, \"gradcam.jpg\")\n",
    "#     grayscale_name = os.path.join(img_dir, \"grayscale.jpg\")\n",
    "#     grayscale_npy_name = os.path.join(img_dir, \"grayscale.npy\")\n",
    "#     scores_name = os.path.join(img_dir, \"scores.npy\")\n",
    "#     info_name = os.path.join(img_dir, \"info.txt\")\n",
    "\n",
    "#     # Save the images and results\n",
    "#     img.save(img_name)\n",
    "#     Image.fromarray(gradcam_result).save(gradcam_name)\n",
    "#     Image.fromarray((grayscale_cams[0] * 255).astype(np.uint8)).save(grayscale_name)\n",
    "#     np.save(grayscale_npy_name, grayscale_cams[0])\n",
    "\n",
    "#     # Save the scores\n",
    "#     scores = [data[\"score\"] for _, data in predictions.items()]\n",
    "#     np.save(scores_name, scores)\n",
    "\n",
    "#     # Save the other info\n",
    "#     with open(info_name, 'w') as f:\n",
    "#         for index, data in predictions.items():\n",
    "#             label = data[\"label\"]\n",
    "#             score = data[\"score\"]\n",
    "#             f.write(f\"Class {index} ({label}): {score:.2f}\\n\")\n",
    "\n",
    "#     del img, label, img_name, img_tensor, gradcam_result, grayscale_cams, logits, top_indices, predictions, scores, index_description, index_str, description, index, dynamic_targets_for_gradcam\n",
    "#     torch.cuda.empty_cache()\n",
    "#     gc.collect()\n",
    "\n",
    "# tracker.stop()\n",
    "# emissions_data = tracker.get_emissions()\n",
    "\n",
    "# output_dir = \"/home/workstation/code/XAImethods/pytorch-grad-cam/apple\"\n",
    "# tracker = EmissionsTracker(output_dir=output_dir)\n",
    "\n",
    "# print(emissions_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try batch size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from tqdm import tqdm\n",
    "# from collections import defaultdict\n",
    "# import gc\n",
    "# from transformers import MobileViTForImageClassification\n",
    "# import os\n",
    "# from PIL import Image\n",
    "\n",
    "# MAX_FILE_SIZE = 5 * 1024 * 1024  # e.g., 5 MB\n",
    "\n",
    "# def is_valid_image_file(filepath):\n",
    "#     \"\"\"Check if the file is a valid image file.\"\"\"\n",
    "#     try:\n",
    "#         with Image.open(filepath) as img:\n",
    "#             img.verify()  # verify that it is a valid image\n",
    "#         return True\n",
    "#     except:\n",
    "#         return False\n",
    "    \n",
    "# tracker = EmissionsTracker()\n",
    "# tracker.start()\n",
    "\n",
    "# BATCH_SIZE = 100\n",
    "\n",
    "# # Split the dataset into batches\n",
    "# num_batches = len(dataset) // BATCH_SIZE + (1 if len(dataset) % BATCH_SIZE != 0 else 0)\n",
    "\n",
    "# for batch_num in range(num_batches):\n",
    "#     start_idx = batch_num * BATCH_SIZE\n",
    "#     end_idx = min((batch_num + 1) * BATCH_SIZE, len(dataset))\n",
    "\n",
    "#     for idx in range(start_idx, end_idx):\n",
    "#         data = dataset[idx]\n",
    "\n",
    "#         try:\n",
    "\n",
    "\n",
    "#             # Load the model and send it to the appropriate device\n",
    "#             model = MobileViTForImageClassification.from_pretrained(\"apple/mobilevit-small\").to(device)\n",
    "#             target_layer = model.mobilevit.conv_1x1_exp\n",
    "\n",
    "#             # Define the transformation to convert images to tensor\n",
    "#             transform = transforms.ToTensor()\n",
    "\n",
    "#             # Define the directory to save results\n",
    "#             save_dir = \"/home/workstation/code/XAImethods/pytorch-grad-cam/apple/mobilevit-small\"\n",
    "#             # Ensure the directory exists\n",
    "#             if not os.path.exists(save_dir):\n",
    "#                 os.makedirs(save_dir)\n",
    "#             # Convert any grayscale image to RGB\n",
    "#             def ensure_rgb(img):\n",
    "#                 if img.mode != 'RGB':\n",
    "#                     return img.convert('RGB')\n",
    "#                 return img\n",
    "\n",
    "#             # Iterate over all images in the dataset\n",
    "#             for idx, (img, label, filename) in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "\n",
    "#                 torch.cuda.empty_cache()\n",
    "#                 img = ensure_rgb(img)  # Ensure the image is in RGB format\n",
    "#                 img_tensor = transform(img).to(device)\n",
    "#                 # Dynamically generate targets_for_gradcam based on model's prediction\n",
    "#                 #dynamic_targets_for_gradcam = get_top_k_targets(model, img_tensor)\n",
    "\n",
    "#                 # 使用标签获取索引和描述\n",
    "#                 index_description = label_to_index_description.get(label)\n",
    "#                 if index_description is None:\n",
    "#                     print(f\"Warning: Label '{label}' not found in the JSON file!\")\n",
    "#                     continue\n",
    "                \n",
    "#                 index_str, description = index_description\n",
    "#                 index = int(index_str)  # 将字符串索引转换为整数\n",
    "\n",
    "#                 dynamic_targets_for_gradcam = [ClassifierOutputTarget(index)]\n",
    "\n",
    "#                 gradcam_result, grayscale_cams = run_grad_cam_on_image(\n",
    "#                     model=model,\n",
    "#                     target_layer=target_layer,\n",
    "#                     targets_for_gradcam=dynamic_targets_for_gradcam,\n",
    "#                     input_tensor=img_tensor,\n",
    "#                     input_image=img,\n",
    "#                     reshape_transform=None\n",
    "#                 )\n",
    "\n",
    "#                 # Extract top predictions\n",
    "#                 logits = model(img_tensor.unsqueeze(0)).logits\n",
    "#                 top_indices = logits[0].argsort(descending=True)[:5].cpu().numpy()\n",
    "#                 predictions = {index: {\"score\": logits[0][index].item(), \"label\": model.config.id2label[index]} for index in top_indices}\n",
    "                \n",
    "#                 # Define individual directory for this image using the original filename\n",
    "#                 img_dir = os.path.join(save_dir, filename.rsplit('.', 1)[0])  # Remove file extension from filename\n",
    "#                 if not os.path.exists(img_dir):\n",
    "#                     os.makedirs(img_dir)\n",
    "                \n",
    "#                 # Define file names\n",
    "#                 img_name = os.path.join(img_dir, \"original.jpg\")\n",
    "#                 gradcam_name = os.path.join(img_dir, \"gradcam.jpg\")\n",
    "#                 grayscale_name = os.path.join(img_dir, \"grayscale.jpg\")\n",
    "#                 grayscale_npy_name = os.path.join(img_dir, \"grayscale.npy\")\n",
    "#                 scores_name = os.path.join(img_dir, \"scores.npy\")\n",
    "#                 info_name = os.path.join(img_dir, \"info.txt\")\n",
    "\n",
    "#                 # Save the images and results\n",
    "#                 img.save(img_name)\n",
    "#                 Image.fromarray(gradcam_result).save(gradcam_name)\n",
    "#                 Image.fromarray((grayscale_cams[0] * 255).astype(np.uint8)).save(grayscale_name)\n",
    "#                 np.save(grayscale_npy_name, grayscale_cams[0])\n",
    "\n",
    "#                 # Save the scores\n",
    "#                 scores = [data[\"score\"] for _, data in predictions.items()]\n",
    "#                 np.save(scores_name, scores)\n",
    "\n",
    "#                 # Save the other info\n",
    "#                 with open(info_name, 'w') as f:\n",
    "#                     for index, data in predictions.items():\n",
    "#                         label = data[\"label\"]\n",
    "#                         score = data[\"score\"]\n",
    "#                         f.write(f\"Class {index} ({label}): {score:.2f}\\n\")\n",
    "#         except RuntimeError as e:\n",
    "#             if \"CUDA out of memory\" in str(e):\n",
    "#                 print(f\"CUDA OutOfMemoryError encountered for file: {filename}\")\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 raise e\n",
    "\n",
    "#         #del img, label, img_name, img_tensor, gradcam_result, grayscale_cams, logits, top_indices, predictions, scores, index_description, index_str, description, index, dynamic_targets_for_gradcam\n",
    "#         torch.cuda.empty_cache()\n",
    "#     # Clean up after processing the batch\n",
    "#     del model\n",
    "#     torch.cuda.empty_cache()\n",
    "#     gc.collect()\n",
    "\n",
    "#     # Reload the model for the next batch\n",
    "#     model = MobileViTForImageClassification.from_pretrained(\"apple/mobilevit-small\").to(device)\n",
    "\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "# tracker.stop()\n",
    "# emissions_data = tracker.get_emissions()\n",
    "\n",
    "# output_dir = \"/home/workstation/code/XAImethods/pytorch-grad-cam/apple\"\n",
    "# tracker = EmissionsTracker(output_dir=output_dir)\n",
    "\n",
    "# print(emissions_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 11:06:30] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 11:06:30] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 11:06:30] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 11:06:30] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 11:06:30] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon INFO @ 11:06:32] CPU Model on constant consumption mode: Intel(R) Core(TM) i9-9900K CPU @ 3.60GHz\n",
      "[codecarbon INFO @ 11:06:32] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 11:06:32]   Platform system: Linux-5.15.90.1-microsoft-standard-WSL2-x86_64-with-glibc2.35\n",
      "[codecarbon INFO @ 11:06:32]   Python version: 3.10.9\n",
      "[codecarbon INFO @ 11:06:32]   Available RAM : 15.576 GB\n",
      "[codecarbon INFO @ 11:06:32]   CPU count: 16\n",
      "[codecarbon INFO @ 11:06:32]   CPU model: Intel(R) Core(TM) i9-9900K CPU @ 3.60GHz\n",
      "[codecarbon INFO @ 11:06:32]   GPU count: 1\n",
      "[codecarbon INFO @ 11:06:32]   GPU model: 1 x NVIDIA GeForce RTX 4090\n",
      "  0%|          | 0/39 [00:00<?, ?it/s][codecarbon INFO @ 11:06:50] Energy consumed for RAM : 0.000024 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:06:50] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:06:50] Energy consumed for all CPUs : 0.000198 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:06:50] 0.000222 kWh of electricity used since the begining.\n",
      "  5%|▌         | 2/39 [00:28<08:31, 13.82s/it][codecarbon INFO @ 11:07:05] Energy consumed for RAM : 0.000049 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:07:05] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:07:05] Energy consumed for all CPUs : 0.000396 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:07:05] 0.000445 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 11:07:20] Energy consumed for RAM : 0.000073 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:07:20] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:07:20] Energy consumed for all CPUs : 0.000594 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:07:20] 0.000667 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 11:07:35] Energy consumed for RAM : 0.000097 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:07:35] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:07:35] Energy consumed for all CPUs : 0.000792 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:07:35] 0.000889 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 11:07:50] Energy consumed for RAM : 0.000122 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:07:50] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:07:50] Energy consumed for all CPUs : 0.000990 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:07:50] 0.001111 kWh of electricity used since the begining.\n",
      "  8%|▊         | 3/39 [01:17<18:00, 30.02s/it][codecarbon INFO @ 11:08:05] Energy consumed for RAM : 0.000146 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:08:05] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:08:05] Energy consumed for all CPUs : 0.001188 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:08:05] 0.001334 kWh of electricity used since the begining.\n",
      " 13%|█▎        | 5/39 [01:44<11:11, 19.75s/it][codecarbon INFO @ 11:08:20] Energy consumed for RAM : 0.000170 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:08:20] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:08:20] Energy consumed for all CPUs : 0.001386 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:08:20] 0.001556 kWh of electricity used since the begining.\n",
      " 15%|█▌        | 6/39 [01:52<08:48, 16.01s/it][codecarbon INFO @ 11:08:35] Energy consumed for RAM : 0.000195 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:08:35] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:08:35] Energy consumed for all CPUs : 0.001583 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:08:35] 0.001778 kWh of electricity used since the begining.\n",
      " 21%|██        | 8/39 [02:11<06:24, 12.40s/it][codecarbon INFO @ 11:08:50] Energy consumed for RAM : 0.000219 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:08:50] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:08:50] Energy consumed for all CPUs : 0.001781 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:08:50] 0.002000 kWh of electricity used since the begining.\n",
      " 23%|██▎       | 9/39 [02:21<05:44, 11.49s/it][codecarbon INFO @ 11:09:05] Energy consumed for RAM : 0.000243 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:09:05] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:09:05] Energy consumed for all CPUs : 0.001979 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:09:05] 0.002222 kWh of electricity used since the begining.\n",
      " 26%|██▌       | 10/39 [02:33<05:39, 11.71s/it][codecarbon INFO @ 11:09:20] Energy consumed for RAM : 0.000267 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:09:20] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:09:20] Energy consumed for all CPUs : 0.002177 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:09:20] 0.002444 kWh of electricity used since the begining.\n",
      " 28%|██▊       | 11/39 [02:50<06:11, 13.27s/it][codecarbon INFO @ 11:09:35] Energy consumed for RAM : 0.000292 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:09:35] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:09:35] Energy consumed for all CPUs : 0.002375 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:09:35] 0.002667 kWh of electricity used since the begining.\n",
      " 31%|███       | 12/39 [03:06<06:22, 14.18s/it][codecarbon INFO @ 11:09:50] Energy consumed for RAM : 0.000316 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:09:50] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:09:50] Energy consumed for all CPUs : 0.002573 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:09:50] 0.002889 kWh of electricity used since the begining.\n",
      " 33%|███▎      | 13/39 [03:16<05:37, 13.00s/it][codecarbon INFO @ 11:10:05] Energy consumed for RAM : 0.000340 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:10:05] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:10:05] Energy consumed for all CPUs : 0.002771 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:10:05] 0.003111 kWh of electricity used since the begining.\n",
      " 38%|███▊      | 15/39 [03:40<04:53, 12.23s/it][codecarbon INFO @ 11:10:20] Energy consumed for RAM : 0.000365 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:10:20] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:10:20] Energy consumed for all CPUs : 0.002969 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:10:20] 0.003334 kWh of electricity used since the begining.\n",
      " 41%|████      | 16/39 [03:49<04:20, 11.31s/it][codecarbon INFO @ 11:10:35] Energy consumed for RAM : 0.000389 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:10:35] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:10:35] Energy consumed for all CPUs : 0.003167 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:10:35] 0.003556 kWh of electricity used since the begining.\n",
      " 46%|████▌     | 18/39 [04:10<03:45, 10.73s/it][codecarbon INFO @ 11:10:50] Energy consumed for RAM : 0.000413 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:10:50] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:10:50] Energy consumed for all CPUs : 0.003364 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:10:50] 0.003778 kWh of electricity used since the begining.\n",
      " 51%|█████▏    | 20/39 [04:29<03:13, 10.18s/it][codecarbon INFO @ 11:11:05] Energy consumed for RAM : 0.000438 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:11:05] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:11:05] Energy consumed for all CPUs : 0.003562 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:11:05] 0.004000 kWh of electricity used since the begining.\n",
      " 54%|█████▍    | 21/39 [04:38<02:57,  9.84s/it][codecarbon INFO @ 11:11:20] Energy consumed for RAM : 0.000462 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:11:20] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:11:20] Energy consumed for all CPUs : 0.003760 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:11:20] 0.004222 kWh of electricity used since the begining.\n",
      " 59%|█████▉    | 23/39 [04:56<02:30,  9.40s/it][codecarbon INFO @ 11:11:35] Energy consumed for RAM : 0.000486 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:11:35] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:11:35] Energy consumed for all CPUs : 0.003958 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:11:35] 0.004444 kWh of electricity used since the begining.\n",
      " 64%|██████▍   | 25/39 [05:14<02:07,  9.11s/it][codecarbon INFO @ 11:11:50] Energy consumed for RAM : 0.000511 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:11:50] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:11:50] Energy consumed for all CPUs : 0.004156 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:11:50] 0.004667 kWh of electricity used since the begining.\n",
      " 67%|██████▋   | 26/39 [05:25<02:07,  9.80s/it][codecarbon INFO @ 11:12:05] Energy consumed for RAM : 0.000535 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:12:05] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:12:05] Energy consumed for all CPUs : 0.004354 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:12:05] 0.004889 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 11:12:20] Energy consumed for RAM : 0.000559 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:12:20] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:12:20] Energy consumed for all CPUs : 0.004552 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:12:20] 0.005111 kWh of electricity used since the begining.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA OutOfMemoryError encountered for file: ILSVRC2012_val_00005196.JPEG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 27/39 [05:54<03:08, 15.67s/it][codecarbon INFO @ 11:12:35] Energy consumed for RAM : 0.000584 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:12:35] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:12:35] Energy consumed for all CPUs : 0.004750 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:12:35] 0.005333 kWh of electricity used since the begining.\n",
      " 74%|███████▍  | 29/39 [06:11<02:00, 12.09s/it][codecarbon INFO @ 11:12:50] Energy consumed for RAM : 0.000608 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:12:50] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:12:50] Energy consumed for all CPUs : 0.004948 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:12:50] 0.005555 kWh of electricity used since the begining.\n",
      " 77%|███████▋  | 30/39 [06:21<01:40, 11.20s/it][codecarbon INFO @ 11:13:05] Energy consumed for RAM : 0.000632 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:13:05] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:13:05] Energy consumed for all CPUs : 0.005146 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:13:05] 0.005778 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 11:13:20] Energy consumed for RAM : 0.000656 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:13:20] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:13:20] Energy consumed for all CPUs : 0.005344 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:13:20] 0.006000 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 11:13:35] Energy consumed for RAM : 0.000681 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:13:35] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:13:35] Energy consumed for all CPUs : 0.005541 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:13:35] 0.006222 kWh of electricity used since the begining.\n",
      " 82%|████████▏ | 32/39 [07:11<01:57, 16.77s/it][codecarbon INFO @ 11:13:50] Energy consumed for RAM : 0.000705 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:13:50] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:13:50] Energy consumed for all CPUs : 0.005739 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:13:50] 0.006444 kWh of electricity used since the begining.\n",
      " 87%|████████▋ | 34/39 [07:29<01:04, 12.91s/it][codecarbon INFO @ 11:14:05] Energy consumed for RAM : 0.000729 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:14:05] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:14:05] Energy consumed for all CPUs : 0.005937 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:14:05] 0.006667 kWh of electricity used since the begining.\n",
      " 90%|████████▉ | 35/39 [07:39<00:48, 12.06s/it][codecarbon INFO @ 11:14:20] Energy consumed for RAM : 0.000754 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:14:20] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:14:20] Energy consumed for all CPUs : 0.006135 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:14:20] 0.006889 kWh of electricity used since the begining.\n",
      " 92%|█████████▏| 36/39 [07:48<00:33, 11.01s/it][codecarbon INFO @ 11:14:35] Energy consumed for RAM : 0.000778 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:14:35] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:14:35] Energy consumed for all CPUs : 0.006333 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:14:35] 0.007111 kWh of electricity used since the begining.\n",
      " 97%|█████████▋| 38/39 [08:13<00:11, 11.61s/it][codecarbon INFO @ 11:14:50] Energy consumed for RAM : 0.000802 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:14:50] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:14:50] Energy consumed for all CPUs : 0.006531 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:14:50] 0.007333 kWh of electricity used since the begining.\n",
      "100%|██████████| 39/39 [08:23<00:00, 12.90s/it]\n",
      "[codecarbon INFO @ 11:14:58] Energy consumed for RAM : 0.000815 kWh. RAM Power : 5.841164588928223 W\n",
      "[codecarbon INFO @ 11:14:58] Energy consumed for all GPUs : 0.000000 kWh. All GPUs Power : 0.0 W\n",
      "[codecarbon INFO @ 11:14:58] Energy consumed for all CPUs : 0.006637 kWh. All CPUs Power : 47.5 W\n",
      "[codecarbon INFO @ 11:14:58] 0.007452 kWh of electricity used since the begining.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'EmissionsTracker' object has no attribute 'get_emissions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/workstation/code/XAImethods/pytorch-grad-cam/tutorials/dev3.ipynb 单元格 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/workstation/code/XAImethods/pytorch-grad-cam/tutorials/dev3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=101'>102</a>\u001b[0m     gc\u001b[39m.\u001b[39mcollect()\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/workstation/code/XAImethods/pytorch-grad-cam/tutorials/dev3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=103'>104</a>\u001b[0m tracker\u001b[39m.\u001b[39mstop()\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/workstation/code/XAImethods/pytorch-grad-cam/tutorials/dev3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=104'>105</a>\u001b[0m emissions_data \u001b[39m=\u001b[39m tracker\u001b[39m.\u001b[39;49mget_emissions()\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/workstation/code/XAImethods/pytorch-grad-cam/tutorials/dev3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=106'>107</a>\u001b[0m output_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/home/workstation/code/XAImethods/pytorch-grad-cam/apple\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/workstation/code/XAImethods/pytorch-grad-cam/tutorials/dev3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=107'>108</a>\u001b[0m tracker \u001b[39m=\u001b[39m EmissionsTracker(output_dir\u001b[39m=\u001b[39moutput_dir)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EmissionsTracker' object has no attribute 'get_emissions'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。请查看单元格中的代码，以确定故障的可能原因。有关详细信息，请单击 <a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>。有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "from transformers import MobileViTForImageClassification\n",
    "from PIL import Image\n",
    "\n",
    "def ensure_rgb(img):\n",
    "    if img.mode != 'RGB':\n",
    "        return img.convert('RGB')\n",
    "    return img\n",
    "\n",
    "def is_valid_image_file(filepath):\n",
    "    \"\"\"Check if the file is a valid image file.\"\"\"\n",
    "    try:\n",
    "        with Image.open(filepath) as img:\n",
    "            img.verify()  # verify that it is a valid image\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "num_batches = len(dataset) // BATCH_SIZE + (1 if len(dataset) % BATCH_SIZE != 0 else 0)\n",
    "\n",
    "save_dir = \"/home/workstation/code/XAImethods/pytorch-grad-cam/apple/mobilevit-small\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "tracker = EmissionsTracker()\n",
    "tracker.start()\n",
    "\n",
    "for batch_num in tqdm(range(num_batches)):\n",
    "    start_idx = batch_num * BATCH_SIZE\n",
    "    end_idx = min((batch_num + 1) * BATCH_SIZE, len(dataset))\n",
    "\n",
    "    model = MobileViTForImageClassification.from_pretrained(\"apple/mobilevit-small\").to(device)\n",
    "    target_layer = model.mobilevit.conv_1x1_exp\n",
    "    transform = transforms.ToTensor()\n",
    "\n",
    "    for idx in range(start_idx, end_idx):\n",
    "        img, label, filename = dataset[idx]\n",
    "        try:\n",
    "            torch.cuda.empty_cache()\n",
    "            img = ensure_rgb(img)\n",
    "            img_tensor = transform(img).to(device)\n",
    "\n",
    "            index_description = label_to_index_description.get(label)\n",
    "            if index_description is None:\n",
    "                print(f\"Warning: Label '{label}' not found in the JSON file!\")\n",
    "                continue\n",
    "\n",
    "            index_str, description = index_description\n",
    "            index = int(index_str)\n",
    "            dynamic_targets_for_gradcam = [ClassifierOutputTarget(index)]\n",
    "\n",
    "            gradcam_result, grayscale_cams = run_grad_cam_on_image(\n",
    "                model=model,\n",
    "                target_layer=target_layer,\n",
    "                targets_for_gradcam=dynamic_targets_for_gradcam,\n",
    "                input_tensor=img_tensor,\n",
    "                input_image=img,\n",
    "                reshape_transform=None\n",
    "            )\n",
    "\n",
    "            logits = model(img_tensor.unsqueeze(0)).logits\n",
    "            top_indices = logits[0].argsort(descending=True)[:5].cpu().numpy()\n",
    "            predictions = {index: {\"score\": logits[0][index].item(), \"label\": model.config.id2label[index]} for index in top_indices}\n",
    "            \n",
    "            img_dir = os.path.join(save_dir, filename.rsplit('.', 1)[0])\n",
    "            if not os.path.exists(img_dir):\n",
    "                os.makedirs(img_dir)\n",
    "\n",
    "            img_name = os.path.join(img_dir, \"original.jpg\")\n",
    "            gradcam_name = os.path.join(img_dir, \"gradcam.jpg\")\n",
    "            grayscale_name = os.path.join(img_dir, \"grayscale.jpg\")\n",
    "            grayscale_npy_name = os.path.join(img_dir, \"grayscale.npy\")\n",
    "            scores_name = os.path.join(img_dir, \"scores.npy\")\n",
    "            info_name = os.path.join(img_dir, \"info.txt\")\n",
    "\n",
    "            img.save(img_name)\n",
    "            Image.fromarray(gradcam_result).save(gradcam_name)\n",
    "            Image.fromarray((grayscale_cams[0] * 255).astype(np.uint8)).save(grayscale_name)\n",
    "            np.save(grayscale_npy_name, grayscale_cams[0])\n",
    "\n",
    "            scores = [data[\"score\"] for _, data in predictions.items()]\n",
    "            np.save(scores_name, scores)\n",
    "\n",
    "            with open(info_name, 'w') as f:\n",
    "                for index, data in predictions.items():\n",
    "                    label = data[\"label\"]\n",
    "                    score = data[\"score\"]\n",
    "                    f.write(f\"Class {index} ({label}): {score:.2f}\\n\")\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            if \"CUDA out of memory\" in str(e):\n",
    "                print(f\"CUDA OutOfMemoryError encountered for file: {filename}\")\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "    # del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "tracker.stop()\n",
    "emissions_data = tracker.get_emissions()\n",
    "\n",
    "output_dir = \"/home/workstation/code/XAImethods/pytorch-grad-cam/apple\"\n",
    "tracker = EmissionsTracker(output_dir=output_dir)\n",
    "\n",
    "print(emissions_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
